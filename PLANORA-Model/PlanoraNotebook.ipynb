{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca730399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing columns: ['tech_spend', 'music_freq', 'sports_hours', 'edu_freq', 'health_priority']. Generating synthetic dataset.\n",
      "First 5 rows of the dataset:\n",
      "   age  gender  tech_spend  music_freq  sports_hours  business_interest  \\\n",
      "0   56    Male           1           5             2                  2   \n",
      "1   46   Other           5           3             4                  1   \n",
      "2   32  Female           5           5             1                  5   \n",
      "3   60    Male           4           5             5                  1   \n",
      "4   25   Other           2           5             2                  2   \n",
      "\n",
      "   edu_freq  food_interest  health_priority preferred_category  \n",
      "0         4              5                5               Food  \n",
      "1         3              2                5             Health  \n",
      "2         5              5                2               Food  \n",
      "3         2              3                5               Tech  \n",
      "4         2              5                4               Food  \n",
      "\n",
      "Missing values:\n",
      "age                   0\n",
      "gender                0\n",
      "tech_spend            0\n",
      "music_freq            0\n",
      "sports_hours          0\n",
      "business_interest     0\n",
      "edu_freq              0\n",
      "food_interest         0\n",
      "health_priority       0\n",
      "preferred_category    0\n",
      "dtype: int64\n",
      "\n",
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   age                 250 non-null    int32 \n",
      " 1   gender              250 non-null    object\n",
      " 2   tech_spend          250 non-null    int32 \n",
      " 3   music_freq          250 non-null    int32 \n",
      " 4   sports_hours        250 non-null    int32 \n",
      " 5   business_interest   250 non-null    int32 \n",
      " 6   edu_freq            250 non-null    int32 \n",
      " 7   food_interest       250 non-null    int32 \n",
      " 8   health_priority     250 non-null    int32 \n",
      " 9   preferred_category  250 non-null    object\n",
      "dtypes: int32(8), object(2)\n",
      "memory usage: 11.8+ KB\n",
      "None\n",
      "\n",
      "Unique categories in preferred_category:\n",
      "preferred_category\n",
      "Health       39\n",
      "Education    38\n",
      "Business     33\n",
      "Food         33\n",
      "Tech         32\n",
      "Music        29\n",
      "Sports       24\n",
      "Art          22\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Shape of training set: (200, 9)\n",
      "Shape of test set: (50, 9)\n",
      "\n",
      "Baseline Model Accuracies:\n",
      "Logistic Regression: 0.3400\n",
      "k-NN: 0.4400\n",
      "Random Forest: 0.3600\n",
      "\n",
      "Best Logistic Regression Parameters: {'C': 10, 'max_iter': 1000, 'solver': 'liblinear'}\n",
      "Best Logistic Regression CV Accuracy: 0.365\n",
      "\n",
      "Best k-NN Parameters: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "Best k-NN CV Accuracy: 0.305\n",
      "\n",
      "Best Random Forest Parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Best Random Forest CV Accuracy: 0.35000000000000003\n",
      "\n",
      "Best Model: k-NN with CV Accuracy: 0.4400\n",
      "\n",
      "Test Set Evaluation for Best Model:\n",
      "Accuracy: 0.26\n",
      "\n",
      "Confusion Matrix:\n",
      " [[0 0 0 1 1 0 0 1]\n",
      " [0 3 0 0 1 2 2 1]\n",
      " [0 1 3 0 1 1 0 0]\n",
      " [0 1 1 1 1 0 0 3]\n",
      " [1 1 1 1 2 0 1 0]\n",
      " [0 1 1 0 1 1 1 2]\n",
      " [0 0 1 0 0 0 1 0]\n",
      " [1 1 4 0 1 0 0 2]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         Art       0.00      0.00      0.00         3\n",
      "    Business       0.38      0.33      0.35         9\n",
      "   Education       0.27      0.50      0.35         6\n",
      "        Food       0.33      0.14      0.20         7\n",
      "      Health       0.25      0.29      0.27         7\n",
      "       Music       0.25      0.14      0.18         7\n",
      "      Sports       0.20      0.50      0.29         2\n",
      "        Tech       0.22      0.22      0.22         9\n",
      "\n",
      "    accuracy                           0.26        50\n",
      "   macro avg       0.24      0.27      0.23        50\n",
      "weighted avg       0.26      0.26      0.25        50\n",
      "\n",
      "\n",
      "Model and preprocessing objects saved.\n",
      "\n",
      "Sample Input Features:\n",
      "          age  gender  tech_spend  music_freq  sports_hours  \\\n",
      "142 -1.076252       0    1.188557    1.318333     -1.472889   \n",
      "\n",
      "     business_interest  edu_freq  food_interest  health_priority  \n",
      "142          -0.086621  0.575268       0.536801         0.501062  \n",
      "Predicted Category for Sample: Education\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # PLANORA User Category Preference Prediction\n",
    "\n",
    "# ## Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# ## Step 2: Load or Generate Data\n",
    "# Try loading the dataset. If itâ€™s missing or has incorrect features, generate a synthetic dataset with the correct features.\n",
    "def generate_synthetic_dataset(n_samples=250):\n",
    "    categories = ['Tech', 'Music', 'Sports', 'Business', 'Education', 'Art', 'Food', 'Health']\n",
    "    data = {\n",
    "        'age': np.random.randint(18, 66, n_samples),\n",
    "        'gender': np.random.choice(['Male', 'Female', 'Other'], n_samples),\n",
    "        'tech_spend': np.random.randint(1, 6, n_samples),\n",
    "        'music_freq': np.random.randint(1, 6, n_samples),\n",
    "        'sports_hours': np.random.randint(1, 6, n_samples),\n",
    "        'business_interest': np.random.randint(1, 6, n_samples),\n",
    "        'edu_freq': np.random.randint(1, 6, n_samples),\n",
    "        'food_interest': np.random.randint(1, 6, n_samples),\n",
    "        'health_priority': np.random.randint(1, 6, n_samples),\n",
    "        'preferred_category': np.random.choice(categories, n_samples)\n",
    "    }\n",
    "    # Adjust scores to correlate with categories\n",
    "    for i in range(n_samples):\n",
    "        category = data['preferred_category'][i]\n",
    "        if category == 'Tech':\n",
    "            data['tech_spend'][i] = np.random.randint(4, 6)\n",
    "        elif category == 'Music':\n",
    "            data['music_freq'][i] = np.random.randint(4, 6)\n",
    "        elif category == 'Sports':\n",
    "            data['sports_hours'][i] = np.random.randint(4, 6)\n",
    "        elif category == 'Business':\n",
    "            data['business_interest'][i] = np.random.randint(4, 6)\n",
    "        elif category == 'Education':\n",
    "            data['edu_freq'][i] = np.random.randint(4, 6)\n",
    "        elif category == 'Food':\n",
    "            data['food_interest'][i] = np.random.randint(4, 6)\n",
    "        elif category == 'Health':\n",
    "            data['health_priority'][i] = np.random.randint(4, 6)\n",
    "        elif category == 'Art':\n",
    "            data['food_interest'][i] = np.random.randint(3, 6)  # Art may correlate with food\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Load or generate dataset\n",
    "dataset_path = 'user_preferences_dataset.csv'\n",
    "required_columns = ['age', 'gender', 'tech_spend', 'music_freq', 'sports_hours', \n",
    "                    'business_interest', 'edu_freq', 'food_interest', 'health_priority', \n",
    "                    'preferred_category']\n",
    "\n",
    "if os.path.exists(dataset_path):\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    missing_cols = [col for col in required_columns if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Missing columns: {missing_cols}. Generating synthetic dataset.\")\n",
    "        df = generate_synthetic_dataset()\n",
    "else:\n",
    "    print(\"Dataset not found. Generating synthetic dataset.\")\n",
    "    df = generate_synthetic_dataset()\n",
    "\n",
    "# Save the dataset for reference\n",
    "df.to_csv('user_preferences_dataset.csv', index=False)\n",
    "\n",
    "# Display dataset info\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nDataset info:\")\n",
    "print(df.info())\n",
    "print(\"\\nUnique categories in preferred_category:\")\n",
    "print(df['preferred_category'].value_counts())\n",
    "\n",
    "# ## Step 3: Preprocess Data\n",
    "# Encode categorical variables, scale numerical features, and split data.\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('preferred_category', axis=1)\n",
    "y = df['preferred_category']\n",
    "\n",
    "# Encode categorical variables\n",
    "le_gender = LabelEncoder()\n",
    "X['gender'] = le_gender.fit_transform(X['gender'])\n",
    "\n",
    "le_category = LabelEncoder()\n",
    "y = le_category.fit_transform(y)\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_cols = ['age', 'tech_spend', 'music_freq', 'sports_hours', \n",
    "                  'business_interest', 'edu_freq', 'food_interest', 'health_priority']\n",
    "scaler = StandardScaler()\n",
    "X[numerical_cols] = scaler.fit_transform(X[numerical_cols])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"\\nShape of training set:\", X_train.shape)\n",
    "print(\"Shape of test set:\", X_test.shape)\n",
    "\n",
    "# ## Step 4: Train Initial Models\n",
    "# Train baseline models: Logistic Regression, k-NN, and Random Forest.\n",
    "\n",
    "# Dictionary to store model performance\n",
    "model_scores = {}\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "model_scores['Logistic Regression'] = accuracy_score(y_test, y_pred_lr)\n",
    "\n",
    "# k-Nearest Neighbors\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "model_scores['k-NN'] = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "model_scores['Random Forest'] = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "# Display baseline accuracies\n",
    "print(\"\\nBaseline Model Accuracies:\")\n",
    "for model, score in model_scores.items():\n",
    "    print(f\"{model}: {score:.4f}\")\n",
    "\n",
    "# ## Step 5: Hyperparameter Tuning\n",
    "# Tune models using GridSearchCV.\n",
    "\n",
    "# Logistic Regression Tuning\n",
    "lr_params = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "lr_grid = GridSearchCV(LogisticRegression(random_state=42), lr_params, cv=5, scoring='accuracy')\n",
    "lr_grid.fit(X_train, y_train)\n",
    "model_scores['Tuned Logistic Regression'] = lr_grid.best_score_\n",
    "print(\"\\nBest Logistic Regression Parameters:\", lr_grid.best_params_)\n",
    "print(\"Best Logistic Regression CV Accuracy:\", lr_grid.best_score_)\n",
    "\n",
    "# k-NN Tuning\n",
    "knn_params = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "knn_grid = GridSearchCV(KNeighborsClassifier(), knn_params, cv=5, scoring='accuracy')\n",
    "knn_grid.fit(X_train, y_train)\n",
    "model_scores['Tuned k-NN'] = knn_grid.best_score_\n",
    "print(\"\\nBest k-NN Parameters:\", knn_grid.best_params_)\n",
    "print(\"Best k-NN CV Accuracy:\", knn_grid.best_score_)\n",
    "\n",
    "# Random Forest Tuning\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "rf_grid = GridSearchCV(RandomForestClassifier(random_state=42), rf_params, cv=5, scoring='accuracy')\n",
    "rf_grid.fit(X_train, y_train)\n",
    "model_scores['Tuned Random Forest'] = rf_grid.best_score_\n",
    "print(\"\\nBest Random Forest Parameters:\", rf_grid.best_params_)\n",
    "print(\"Best Random Forest CV Accuracy:\", rf_grid.best_score_)\n",
    "\n",
    "# ## Step 6: Evaluate Models\n",
    "# Evaluate the best model on the test set.\n",
    "\n",
    "# Select the best model\n",
    "best_model_name = max(model_scores, key=model_scores.get)\n",
    "print(f\"\\nBest Model: {best_model_name} with CV Accuracy: {model_scores[best_model_name]:.4f}\")\n",
    "\n",
    "# Get the best model\n",
    "if best_model_name.startswith('Tuned Logistic'):\n",
    "    best_model = lr_grid.best_estimator_\n",
    "elif best_model_name.startswith('Tuned k-NN'):\n",
    "    best_model = knn_grid.best_estimator_\n",
    "else:\n",
    "    best_model = rf_grid.best_estimator_\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "print(\"\\nTest Set Evaluation for Best Model:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_best))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_best))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_best, target_names=le_category.classes_))\n",
    "\n",
    "# ## Step 7: Save and Predict\n",
    "# Save model and preprocessing objects, and test prediction.\n",
    "\n",
    "# Save objects\n",
    "joblib.dump(best_model, 'best_category_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "joblib.dump(le_gender, 'le_gender.pkl')\n",
    "joblib.dump(le_category, 'le_category.pkl')\n",
    "\n",
    "print(\"\\nModel and preprocessing objects saved.\")\n",
    "\n",
    "# Test prediction\n",
    "sample = X_test.iloc[0:1].copy()\n",
    "print(\"\\nSample Input Features:\")\n",
    "print(sample)\n",
    "sample_pred = best_model.predict(sample)\n",
    "sample_category = le_category.inverse_transform(sample_pred)[0]\n",
    "print(f\"Predicted Category for Sample: {sample_category}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
